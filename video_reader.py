"""
VIDEO READER FOR OFFLINE VIDEO PROCESSING
==========================================

ƒê·ªçc video offline NHANH NH·∫§T c√≥ th·ªÉ - KH√îNG gi·∫≠t, KH√îNG nh·∫£y frame

NGUY√äN T·∫ÆC:
‚úÖ ƒê·ªçc frame nhanh nh·∫•t c√≥ th·ªÉ (NO time.sleep())
‚úÖ FPS ch·ªâ ƒë·ªÉ t√≠nh timestamp, KH√îNG ƒë·ªÉ delay
‚úÖ M·ªçi frame ƒë∆∞·ª£c ƒë·ªçc ƒë√∫ng th·ª© t·ª±
‚úÖ Timestamp = frame_number / fps (KH√îNG d√πng time.time())
‚úÖ Video reader C·ª∞C NH·∫∏ - ch·ªâ ƒë·ªçc v√† push

‚ùå KH√îNG time.sleep()
‚ùå KH√îNG skip frame ·ªü ƒë√¢y
‚ùå KH√îNG ch·∫°y AI
‚ùå KH√îNG resize/modify frame
‚ùå KH√îNG d√πng time.time() cho timestamp
"""

import cv2
import threading
from collections import deque
import time
import queue


class OfflineVideoReader:
    """
    Video reader t·ªëi ∆∞u cho OFFLINE VIDEO (kh√¥ng ph·∫£i realtime camera)

    ƒê·ªçc video nhanh nh·∫•t c√≥ th·ªÉ, kh√¥ng delay theo FPS.
    Worker ph√≠a sau ch·∫≠m th√¨ queue s·∫Ω ƒë·∫ßy v√† t·ª± ƒëi·ªÅu ch·ªânh.
    """

    def __init__(self, video_path, detection_queue, original_frame_buffer,
                 detection_frequency=1, detection_scale=1.0, cap_lock=None):
        """
        Args:
            video_path: ƒê∆∞·ªùng d·∫´n file video
            detection_queue: Queue ƒë·ªÉ push frame cho detection worker
            original_frame_buffer: Dict buffer l∆∞u frame g·ªëc
            detection_frequency: M·ªói N frame th√¨ push v√†o detection_queue
            detection_scale: Scale ƒë·ªÉ resize frame cho detection (0.5 = 50%)
            cap_lock: Lock ƒë·ªÉ thread-safe (n·∫øu c√≥)
        """
        self.video_path = video_path
        self.detection_queue = detection_queue
        self.original_frame_buffer = original_frame_buffer
        self.detection_frequency = detection_frequency
        self.detection_scale = detection_scale
        self.cap_lock = cap_lock if cap_lock else threading.Lock()

        self.cap = None
        self.fps = 30.0
        self.frame_count_total = 0
        self.running = False
        self.thread = None
        self.loop = True  # M·∫∑c ƒë·ªãnh loop video

    def open_video(self):
        """M·ªü video v√† l·∫•y th√¥ng tin"""
        self.cap = cv2.VideoCapture(self.video_path)

        if not self.cap.isOpened():
            raise ValueError(f"Cannot open video: {self.video_path}")

        # L·∫•y FPS t·ª´ video
        self.fps = self.cap.get(cv2.CAP_PROP_FPS)
        if self.fps <= 0 or self.fps > 1000:
            self.fps = 30.0
            print(f"[VIDEO READER] ‚ö†Ô∏è  Invalid FPS, using default: {self.fps}")

        # L·∫•y t·ªïng s·ªë frame
        self.frame_count_total = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))

        width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

        print(f"[VIDEO READER] ‚úÖ Video opened: {width}x{height} @ {self.fps:.2f} FPS")
        print(f"[VIDEO READER] Total frames: {self.frame_count_total}")
        print(f"[VIDEO READER] Duration: {self.frame_count_total / self.fps:.2f}s")

        return self.cap

    def calculate_timestamp(self, frame_number):
        """
        T√≠nh timestamp CH√çNH X√ÅC t·ª´ frame number v√† FPS

        ‚úÖ ƒê√öNG: timestamp = frame_number / fps
        ‚ùå SAI: timestamp = time.time()
        """
        return frame_number / self.fps

    def reset(self):
        """Reset video v·ªÅ ƒë·∫ßu ƒë·ªÉ loop"""
        if self.cap and self.cap.isOpened():
            self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
            print(f"[VIDEO READER] üîÑ Reset video to beginning")

    def read_frame(self):
        """
        ƒê·ªçc 1 frame t·ª´ video

        Returns:
            (success, frame, frame_number)
        """
        if not self.cap or not self.cap.isOpened():
            return False, None, 0

        with self.cap_lock:
            ret, frame = self.cap.read()
            if ret:
                # L·∫•y frame number hi·ªán t·∫°i
                frame_number = int(self.cap.get(cv2.CAP_PROP_POS_FRAMES))
                return True, frame, frame_number
            else:
                return False, None, 0

    def video_reader_thread(self, stream_queue_clean=None, alpr_proactive_queue=None, alpr_frequency=3, active_tracks=None, active_tracks_lock=None):
        """
        THREAD ƒê·ªåC VIDEO OFFLINE - DUAL-STREAM ARCHITECTURE + DIRECT FRAME BUFFERING
        
        Push frame v√†o nhi·ªÅu queue:
        - stream_queue_clean: M·ªçi frame (web stream m∆∞·ª£t)
        - alpr_proactive_queue: M·ªói N frame (ALPR proactive)
        - detection_queue: M·ªói detection_frequency frame (detection)
        - original_frame_buffer[track_id]: M·ªåI frame cho T·∫§T C·∫¢ active tracks (NEW)
        """
        print("[VIDEO READER] üöÄ Thread started - Reading at MAXIMUM speed")
        print(f"[VIDEO READER] Detection frequency: every {self.detection_frequency} frame(s)")
        print(f"[VIDEO READER] Detection scale: {self.detection_scale * 100}%")
        if stream_queue_clean:
            print("[VIDEO READER] ‚úÖ Stream queue enabled (smooth web stream)")
        if alpr_proactive_queue:
            print(f"[VIDEO READER] ‚úÖ ALPR proactive queue enabled (every {alpr_frequency} frames)")
        if active_tracks is not None:
            print("[VIDEO READER] ‚úÖ Active tracks buffering enabled (direct frame buffer)")

        frame_count = 0
        frames_pushed_to_detection = 0

        if 'global' not in self.original_frame_buffer:
            self.original_frame_buffer['global'] = deque(maxlen=150)

        while self.running:
            ret, frame, frame_number = self.read_frame()

            if not ret or frame is None:
                print(f"[VIDEO READER] ‚úÖ Video finished - Read {frame_count} frames")
                print(f"[VIDEO READER] Pushed {frames_pushed_to_detection} frames to detection")
                
                # FIX: Loop video n·∫øu self.loop = True
                if self.loop:
                    print(f"[VIDEO READER] üîÑ Looping video...")
                    self.reset()  # Reset v·ªÅ ƒë·∫ßu video
                    frame_count = 0
                    frames_pushed_to_detection = 0
                    continue
                else:
                    break

            frame_count += 1
            timestamp = self.calculate_timestamp(frame_number)
            original_frame = frame.copy()

            frame_data = {
                'frame': original_frame,
                'frame_id': frame_count,
                'timestamp': timestamp,
                'frame_number': frame_number  # NEW: Store frame_number for debugging
            }

            # Save to global (existing)
            self.original_frame_buffer['global'].append(frame_data)

            # NEW: Save to ALL active track buffers (ƒë·∫£m b·∫£o frames li√™n t·ª•c, kh√¥ng skip)
            if active_tracks_lock:
                with active_tracks_lock:
                    for track_id in list(active_tracks.keys()):
                        if track_id not in self.original_frame_buffer:
                            self.original_frame_buffer[track_id] = deque(maxlen=150)
                        self.original_frame_buffer[track_id].append(frame_data.copy())

            # 1. Push v√†o stream_queue_clean (M·ªåI FRAME - web stream m∆∞·ª£t)
            if stream_queue_clean is not None:
                try:
                    h, w = frame.shape[:2]
                    stream_width = 1280
                    stream_height = int(h * (stream_width / w))
                    stream_frame = cv2.resize(frame, (stream_width, stream_height), interpolation=cv2.INTER_LINEAR)
                    stream_queue_clean.put(stream_frame, block=False)
                except queue.Full:
                    pass

            # 2. Push v√†o alpr_proactive_queue (M·ªñI N FRAME - ALPR proactive)
            if alpr_proactive_queue is not None and frame_count % alpr_frequency == 0:
                try:
                    alpr_proactive_queue.put({
                        'frame': original_frame.copy(),
                        'frame_id': frame_count,
                        'timestamp': timestamp
                    }, block=False)
                except queue.Full:
                    pass

            # 3. Push v√†o detection_queue (M·ªñI DETECTION_FREQUENCY FRAME)
            if frame_count % self.detection_frequency == 0:
                if self.detection_scale < 1.0:
                    h, w = frame.shape[:2]
                    detect_w = int(w * self.detection_scale)
                    detect_h = int(h * self.detection_scale)
                    detect_frame = cv2.resize(frame, (detect_w, detect_h), interpolation=cv2.INTER_LINEAR)
                else:
                    detect_frame = frame

                try:
                    if len(self.detection_queue) < self.detection_queue.maxlen:
                        self.detection_queue.append({
                            'frame': detect_frame,
                            'original': original_frame,
                            'frame_id': frame_count,
                            'frame_number': frame_number,  # ACTUAL frame position in source video
                            'timestamp': timestamp
                        })
                        frames_pushed_to_detection += 1
                    else:
                        time.sleep(0.001)
                except Exception as e:
                    print(f"[VIDEO READER] ‚ö†Ô∏è  Queue error: {e}")

        print(f"[VIDEO READER] üèÅ Thread stopped")
        print(f"[VIDEO READER] Total frames read: {frame_count}")
        print(f"[VIDEO READER] Total frames sent to detection: {frames_pushed_to_detection}")

    def start(self, stream_queue_clean=None, alpr_proactive_queue=None, alpr_frequency=3, active_tracks=None, active_tracks_lock=None):
        """Kh·ªüi ƒë·ªông video reader thread v·ªõi dual-stream support + direct frame buffering"""
        if self.running:
            print("[VIDEO READER] ‚ö†Ô∏è  Already running")
            return

        self.open_video()
        self.running = True
        self.thread = threading.Thread(
            target=self.video_reader_thread,
            kwargs={
                'stream_queue_clean': stream_queue_clean,
                'alpr_proactive_queue': alpr_proactive_queue,
                'alpr_frequency': alpr_frequency,
                'active_tracks': active_tracks,
                'active_tracks_lock': active_tracks_lock
            },
            daemon=True
        )
        self.thread.start()
        print("[VIDEO READER] ‚úÖ Started")

    def stop(self):
        """D·ª´ng video reader thread"""
        if not self.running:
            return

        print("[VIDEO READER] üõë Stopping...")
        self.running = False

        if self.thread:
            self.thread.join(timeout=2.0)

        if self.cap:
            with self.cap_lock:
                self.cap.release()

        print("[VIDEO READER] ‚úÖ Stopped")

    def get_info(self):
        """L·∫•y th√¥ng tin video"""
        return {
            'fps': self.fps,
            'total_frames': self.frame_count_total,
            'duration': self.frame_count_total / self.fps if self.fps > 0 else 0,
            'width': int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH)) if self.cap else 0,
            'height': int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) if self.cap else 0,
        }


# =============================================================================
# HELPER FUNCTION - ƒê·ªÉ thay th·∫ø video_thread() trong app.py
# =============================================================================

def video_reader_thread(video_path, detection_queue, original_frame_buffer,
                       detection_frequency=1, detection_scale=1.0,
                       camera_running_flag=None, cap_lock=None):
    """
    üéØ H√ÄM B·∫ÆT BU·ªòC THEO Y√äU C·∫¶U

    Video reader cho OFFLINE VIDEO - Kh√¥ng gi·∫≠t, kh√¥ng nh·∫£y frame

    Args:
        video_path: ƒê∆∞·ªùng d·∫´n file video
        detection_queue: Queue ƒë·ªÉ push frame cho detection worker (deque)
        original_frame_buffer: Dict buffer l∆∞u frame g·ªëc
        detection_frequency: M·ªói N frame th√¨ push v√†o detection (default=1)
        detection_scale: Scale ƒë·ªÉ resize frame cho detection (default=1.0)
        camera_running_flag: Dict/object c√≥ attribute 'value' ƒë·ªÉ ki·ªÉm tra running state
        cap_lock: Threading lock ƒë·ªÉ thread-safe

    Format d·ªØ li·ªáu frame:
        {
            "frame": numpy.ndarray,      # Frame ƒë√£ resize cho detection
            "original": numpy.ndarray,   # Frame g·ªëc full size
            "frame_id": int,             # S·ªë th·ª© t·ª± frame
            "timestamp": float           # Timestamp = frame_id / fps
        }

    ‚úÖ NGUY√äN T·∫ÆC:
    - ƒê·ªçc nhanh nh·∫•t c√≥ th·ªÉ (NO delay)
    - FPS ch·ªâ ƒë·ªÉ t√≠nh timestamp
    - Kh√¥ng skip frame ·ªü ƒë√¢y
    - Kh√¥ng resize trong reader (ch·ªâ khi push v√†o detection)
    """
    reader = OfflineVideoReader(
        video_path=video_path,
        detection_queue=detection_queue,
        original_frame_buffer=original_frame_buffer,
        detection_frequency=detection_frequency,
        detection_scale=detection_scale,
        cap_lock=cap_lock
    )

    # N·∫øu c√≥ camera_running_flag, override running state
    if camera_running_flag is not None:
        # Gi·∫£ s·ª≠ camera_running_flag l√† dict v·ªõi key 'value' ho·∫∑c object v·ªõi attribute 'value'
        if hasattr(camera_running_flag, 'value'):
            while camera_running_flag.value:
                if not reader.running:
                    reader.start()
                time.sleep(0.1)
            reader.stop()
        else:
            # Ch·∫°y b√¨nh th∆∞·ªùng
            reader.start()
    else:
        reader.start()


# =============================================================================
# EXAMPLE USAGE
# =============================================================================

if __name__ == "__main__":
    """
    Test video reader v·ªõi video m·∫´u
    """
    import time

    # Setup
    detection_queue = deque(maxlen=30)
    original_frame_buffer = {}

    video_path = "test_video.mp4"  # Thay b·∫±ng video c·ªßa b·∫°n

    # T·∫°o reader
    reader = OfflineVideoReader(
        video_path=video_path,
        detection_queue=detection_queue,
        original_frame_buffer=original_frame_buffer,
        detection_frequency=2,  # Push m·ªói 2 frame
        detection_scale=0.5     # Resize 50% cho detection
    )

    # Start
    reader.start()

    # Monitor
    start_time = time.time()
    prev_queue_size = 0

    while reader.running:
        time.sleep(1.0)
        queue_size = len(detection_queue)
        buffer_size = len(original_frame_buffer.get('global', []))
        elapsed = time.time() - start_time

        print(f"[MONITOR] Time: {elapsed:.1f}s | Queue: {queue_size} | Buffer: {buffer_size}")

        # Gi·∫£ l·∫≠p detection worker ƒë·ªçc t·ª´ queue
        if queue_size > 0:
            frame_data = detection_queue.popleft()
            print(f"[WORKER] Processing frame {frame_data['frame_id']} @ {frame_data['timestamp']:.3f}s")

        if queue_size == prev_queue_size == 0 and elapsed > 5:
            # Video ƒë√£ ƒë·ªçc xong v√† queue r·ªóng
            break

        prev_queue_size = queue_size

    reader.stop()
    print("\n‚úÖ Test completed!")