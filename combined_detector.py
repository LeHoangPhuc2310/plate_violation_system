# combined_detector.py
"""
Detector t·ªëi ∆∞u cho web: Nh·∫π, m∆∞·ª£t, t√°ch bi·ªát r√µ r√†ng
- Vehicle Detection & Tracking: Ch·ªâ t√≠nh to√°n tracking v√† detection
- Fast-ALPR: S·ª≠ d·ª•ng PlateDetector t·ª´ detector.py (ƒë√£ ch·∫°y ·ªïn)
"""
import cv2
import numpy as np

# Import YOLO v·ªõi error handling
try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
except Exception as e:
    YOLO_AVAILABLE = False
    print(f"‚ö†Ô∏è  YOLO import failed: {e}")

# Import PlateDetector t·ª´ detector.py (ƒë√£ ch·∫°y ·ªïn)
try:
    from detector import PlateDetector
    PLATE_DETECTOR_AVAILABLE = True
except Exception as e:
    PLATE_DETECTOR_AVAILABLE = False
    print(f"‚ö†Ô∏è  PlateDetector import failed: {e}")

# OC-SORT tracking - T·ªêI ∆ØU CHO WEB
try:
    from oc_sort import OCSort
    OCSORT_AVAILABLE = True
except Exception as e:
    OCSORT_AVAILABLE = False
    # Fallback to ByteTrack
    try:
        from byte_tracker import BYTETracker
        BYTETRACK_AVAILABLE = True
    except:
        BYTETRACK_AVAILABLE = False


class CombinedDetector:
    def __init__(self, yolo_model='yolo11n.pt', device=None):
        """
        Kh·ªüi t·∫°o detector t·ªëi ∆∞u cho web - B·∫ÆT BU·ªòC GPU
        - Vehicle detection: YOLO (nh·∫π, nhanh) - GPU REQUIRED
        - Tracking: OC-SORT ho·∫∑c ByteTrack (m∆∞·ª£t) - GPU REQUIRED
        - Plate reading: Fast-ALPR (ch·ªâ ch·∫°y khi c√≥ xe) - GPU REQUIRED
        """
        # Auto-detect device
        if device is None:
            try:
                import torch
                if torch.cuda.is_available():
                    device = 'cuda'
                    gpu_name = torch.cuda.get_device_name(0)
                    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
                    print(f"üöÄ GPU CUDA detected: {gpu_name} ({gpu_memory:.1f} GB)")
                elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                    device = 'mps'
                    print("üöÄ GPU MPS (Apple Silicon) detected")
                else:
                    device = 'cpu'
                    print("‚ö†Ô∏è  WARNING: No GPU detected!")
            except Exception as e:
                print(f"‚ö†Ô∏è  PyTorch import error: {e}")
                device = 'cpu'
        
        # Cho ph√©p CPU v·ªõi WARNING (kh√¥ng ph·∫£i error)
        if device == 'cpu':
            print("‚ö†Ô∏è  WARNING: CombinedDetector will run on CPU (SLOW performance!)")
            print("‚ö†Ô∏è  For optimal performance, please install CUDA and ensure GPU is available")
            print("‚ö†Ô∏è  Install CUDA: https://developer.nvidia.com/cuda-downloads")
        
        if not YOLO_AVAILABLE:
            raise ImportError("YOLO is not available. Please install: pip install ultralytics")
        
        # ============================================
        # 1. VEHICLE DETECTION (YOLO) - NH·∫∏, NHANH
        # ============================================
        print(f">>> Loading YOLO Vehicle Detector on {device.upper()}...")
        try:
            self.yolo = YOLO(yolo_model)
            self.device = device
        except Exception as e:
            print(f"‚ö†Ô∏è  YOLO model loading failed: {e}")
            raise
        
        # C√°c class ID c·ªßa xe trong COCO dataset
        self.vehicle_classes = {
            2: 'car',
            3: 'motorcycle', 
            5: 'bus',
            7: 'truck'
        }
        
        # ============================================
        # 2. TRACKING - OC-SORT (M·ª∞·ª¢T) ho·∫∑c ByteTrack - C·∫¢I THI·ªÜN ƒê·ªò CH√çNH X√ÅC
        # ============================================
        if OCSORT_AVAILABLE:
            print(">>> Loading OC-SORT (smooth & accurate tracking)...")
            try:
                # C·∫£i thi·ªán tracking: theo k·ªãp xe nhanh h∆°n
                self.oc_sort = OCSort(
                    det_thresh=0.25,   # TƒÉng t·ª´ 0.2 l√™n 0.25 ƒë·ªÉ ch√≠nh x√°c h∆°n
                    max_age=20,        # Gi·∫£m t·ª´ 30 xu·ªëng 20 ƒë·ªÉ ph·∫£n ·ª©ng nhanh h∆°n
                    min_hits=2,        # Gi·∫£m t·ª´ 3 xu·ªëng 2 ƒë·ªÉ confirm track nhanh h∆°n
                    iou_threshold=0.25  # Gi·∫£m t·ª´ 0.3 xu·ªëng 0.25 ƒë·ªÉ d·ªÖ match h∆°n, theo k·ªãp xe nhanh h∆°n
                )
                self.use_ocsort = True
                self.use_bytetrack = False
                print("    ‚úÖ OC-SORT enabled - Tracking ch√≠nh x√°c & m∆∞·ª£t")
            except Exception as e:
                print(f"    ‚ö†Ô∏è  OC-SORT init failed: {e}")
                self.oc_sort = None
                self.use_ocsort = False
                self.use_bytetrack = False
        elif BYTETRACK_AVAILABLE:
            print(">>> Loading ByteTrack (fallback)...")
            try:
                self.byte_tracker = BYTETracker(
                    frame_rate=30,
                    track_thresh=0.25,  # TƒÉng t·ª´ 0.15 l√™n 0.25 ƒë·ªÉ ch√≠nh x√°c h∆°n
                    track_buffer=20,     # Gi·∫£m t·ª´ 30 xu·ªëng 20 ƒë·ªÉ ph·∫£n ·ª©ng nhanh h∆°n
                    match_thresh=0.3     # Gi·∫£m t·ª´ 0.4 xu·ªëng 0.3 ƒë·ªÉ d·ªÖ match h∆°n, theo k·ªãp xe nhanh h∆°n
                )
                self.use_bytetrack = True
                self.use_ocsort = False
                print("    ‚úÖ ByteTrack enabled")
            except Exception as e:
                print(f"    ‚ö†Ô∏è  ByteTrack init failed: {e}")
                self.byte_tracker = None
                self.use_bytetrack = False
                self.use_ocsort = False
        else:
            self.use_ocsort = False
            self.use_bytetrack = False
            print(">>> Using YOLO built-in tracking (fallback)")
        
        # ============================================
        # 3. FAST-ALPR - S·ª¨ D·ª§NG PlateDetector T·ª™ detector.py
        # ============================================
        if not PLATE_DETECTOR_AVAILABLE:
            print("‚ö†Ô∏è  PlateDetector not available - plate detection will be disabled")
            self.plate_detector = None
        else:
            print(f">>> Loading PlateDetector t·ª´ detector.py on {device.upper()}...")
            try:
                # Pass device to PlateDetector (c√≥ th·ªÉ l√† CPU ho·∫∑c GPU)
                self.plate_detector = PlateDetector(device=device)
                print(f"    ‚úÖ PlateDetector loaded on {device.upper()} - S·∫µn s√†ng ƒë·ªçc bi·ªÉn s·ªë")
            except Exception as e:
                print(f"‚ö†Ô∏è  PlateDetector loading failed: {e}")
                print(f"‚ö†Ô∏è  Plate detection will be disabled. System will continue without plate detection.")
                self.plate_detector = None  # Disable plate detection thay v√¨ crash
        
        # Cache bi·ªÉn s·ªë ƒë·ªÉ tr√°nh ƒë·ªçc l·∫°i nhi·ªÅu l·∫ßn
        self.plate_cache = {}  # track_id -> {'plate': str, 'bbox': tuple, 'frame_count': int}
        self.plate_cache_max_age = 30  # Gi·ªØ cache 30 frames
        
        print(">>> ‚úÖ Combined Detector Loaded - T·ªëi ∆∞u cho web!")
    
    def detect(self, frame, enable_plate_detection=True):
        """
        Ph√°t hi·ªán xe v√† bi·ªÉn s·ªë trong frame
        T·ªêI ∆ØU: Ch·ªâ ƒë·ªçc bi·ªÉn s·ªë khi c√≥ ph∆∞∆°ng ti·ªán
        
        Args:
            frame: Frame c·∫ßn detect
            enable_plate_detection: N·∫øu False, ch·ªâ detect xe, kh√¥ng ƒë·ªçc bi·ªÉn s·ªë (t·ªëi ∆∞u t·ªëc ƒë·ªô)
        
        Returns:
            List c√°c dict: {
                'vehicle_bbox': (x1, y1, x2, y2),
                'vehicle_class': 'car/motorcycle/bus/truck',
                'confidence': 0.xx,
                'track_id': int,
                'plate': 'ABC123' ho·∫∑c None,
                'plate_bbox': (x1, y1, x2, y2) ho·∫∑c None
            }
        """
        # ============================================
        # B∆Ø·ªöC 1: DETECT XE B·∫∞NG YOLO (NH·∫∏, NHANH)
        # ============================================
        detections = []
        
        if self.use_ocsort or self.use_bytetrack:
            # D√πng YOLO ch·ªâ ƒë·ªÉ detect (kh√¥ng tracking t√≠ch h·ª£p)
            # T·ªêI ∆ØU GPU: S·ª≠ d·ª•ng FP16 v√† batch processing
            use_half = (self.device == 'cuda')  # FP16 tr√™n GPU CUDA
            
            results = self.yolo.predict(
                frame, 
                verbose=False, 
                classes=list(self.vehicle_classes.keys()),
                device=self.device,  # B·∫ÆT BU·ªòC GPU
                conf=0.3,   # TƒÉng t·ª´ 0.25 l√™n 0.3 ƒë·ªÉ ch√≠nh x√°c h∆°n
                iou=0.5,    # TƒÉng t·ª´ 0.45 l√™n 0.5 ƒë·ªÉ gi·∫£m false positive
                half=use_half,  # FP16 tr√™n GPU - TƒÇNG T·ªêC 2X
                agnostic_nms=True,  # NMS nhanh h∆°n
                max_det=50,  # Gi·ªØ nguy√™n
                imgsz=640,   # T·ªëi ∆∞u cho GPU
                stream=False,
                # T·ªêI ∆ØU GPU: Th√™m c√°c tham s·ªë ƒë·ªÉ tƒÉng t·ªëc
                augment=False,  # T·∫Øt augmentation ƒë·ªÉ tƒÉng t·ªëc
                visualize=False  # T·∫Øt visualization ƒë·ªÉ tƒÉng t·ªëc
            )
            
            if results[0].boxes is not None and len(results[0].boxes) > 0:
                boxes = results[0].boxes
                
                # Chu·∫©n b·ªã d·ªØ li·ªáu cho tracking
                track_inputs = []
                for box in boxes:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    conf = float(box.conf[0].cpu().numpy())
                    cls_id = int(box.cls[0].cpu().numpy())
                    
                    # Ch·ªâ l·∫•y detection c√≥ confidence cao ƒë·ªÉ tracking ch√≠nh x√°c h∆°n
                    if conf >= 0.3 and cls_id in self.vehicle_classes:
                        # ƒê·∫£m b·∫£o bbox h·ª£p l·ªá
                        if x2 > x1 and y2 > y1:
                            track_inputs.append([x1, y1, x2, y2, conf, cls_id])
                
                # Tracking v·ªõi OC-SORT ho·∫∑c ByteTrack
                if len(track_inputs) > 0:
                    track_inputs = np.array(track_inputs, dtype=np.float32)
                    
                    if self.use_ocsort:
                        online_targets = self.oc_sort.update(track_inputs, frame)
                    else:
                        online_targets = self.byte_tracker.update(track_inputs, frame)
                    
                    # Chuy·ªÉn ƒë·ªïi k·∫øt qu·∫£ tracking th√†nh detections
                    for track in online_targets:
                        x1, y1, x2, y2 = track.tlbr.astype(int)
                        track_id = int(track.track_id)
                        conf = float(track.score)
                        cls_id = int(track.cls)
                        
                        # ƒê·∫£m b·∫£o bbox h·ª£p l·ªá v√† n·∫±m trong frame
                        h, w = frame.shape[:2]
                        x1 = max(0, min(x1, w - 1))
                        y1 = max(0, min(y1, h - 1))
                        x2 = max(x1 + 1, min(x2, w))
                        y2 = max(y1 + 1, min(y2, h))
                        
                        if cls_id in self.vehicle_classes and x2 > x1 and y2 > y1:
                            detection = {
                                'vehicle_bbox': (int(x1), int(y1), int(x2), int(y2)),
                                'vehicle_class': self.vehicle_classes[cls_id],
                                'confidence': conf,
                                'track_id': track_id,
                                'plate': None,
                                'plate_bbox': None
                            }
                            detections.append(detection)
        else:
            # Fallback: D√πng YOLO tracking t√≠ch h·ª£p
            results = self.yolo.track(
                frame, 
                persist=True, 
                verbose=False, 
                classes=list(self.vehicle_classes.keys()),
                device=self.device,
                conf=0.25
            )
            
            if results[0].boxes is not None and len(results[0].boxes) > 0:
                boxes = results[0].boxes
                
                for box in boxes:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)
                    cls_id = int(box.cls[0].cpu().numpy())
                    confidence = float(box.conf[0].cpu().numpy())
                    
                    if box.id is not None:
                        track_id = int(box.id[0].cpu().numpy())
                    else:
                        track_id = hash((x1, y1, x2, y2)) % 100000
                    
                    # ƒê·∫£m b·∫£o bbox h·ª£p l·ªá v√† n·∫±m trong frame
                    h, w = frame.shape[:2]
                    x1 = max(0, min(x1, w - 1))
                    y1 = max(0, min(y1, h - 1))
                    x2 = max(x1 + 1, min(x2, w))
                    y2 = max(y1 + 1, min(y2, h))
                    
                    if confidence > 0.3 and cls_id in self.vehicle_classes and x2 > x1 and y2 > y1:
                        detection = {
                            'vehicle_bbox': (int(x1), int(y1), int(x2), int(y2)),
                            'vehicle_class': self.vehicle_classes[cls_id],
                            'confidence': confidence,
                            'track_id': track_id,
                            'plate': None,
                            'plate_bbox': None
                        }
                        detections.append(detection)
        
        # ============================================
        # B∆Ø·ªöC 2: ƒê·ªåC BI·ªÇN S·ªê (CH·ªà KHI C√ì XE) - S·ª¨ D·ª§NG PlateDetector
        # ============================================
        # T·ªêI ∆ØU: Ch·ªâ ƒë·ªçc bi·ªÉn s·ªë cho t·ªëi ƒëa 2 xe m·ªói frame (nh·∫π h∆°n)
        # ∆Øu ti√™n xe ch∆∞a c√≥ bi·ªÉn s·ªë ho·∫∑c bi·ªÉn s·ªë kh√¥ng ƒë·∫ßy ƒë·ªß
        # N·∫øu enable_plate_detection=False, b·ªè qua b∆∞·ªõc n√†y ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô
        if enable_plate_detection and self.plate_detector is not None and len(detections) > 0:
            # L·ªçc xe c·∫ßn ƒë·ªçc bi·ªÉn s·ªë
            plates_to_detect = []
            for det in detections:
                track_id = det['track_id']
                
                # Ki·ªÉm tra cache
                if track_id in self.plate_cache:
                    cached = self.plate_cache[track_id]
                    # N·∫øu cache c√≤n m·ªõi v√† bi·ªÉn s·ªë ƒë·∫ßy ƒë·ªß (>= 6 k√Ω t·ª±), d√πng cache
                    if cached['frame_count'] < self.plate_cache_max_age and len(cached['plate']) >= 6:
                        det['plate'] = cached['plate']
                        det['plate_bbox'] = cached['bbox']
                        continue
                
                # Xe ch∆∞a c√≥ bi·ªÉn s·ªë ho·∫∑c bi·ªÉn s·ªë kh√¥ng ƒë·∫ßy ƒë·ªß
                if not det.get('plate') or len(det.get('plate', '')) < 6:
                    plates_to_detect.append(det)
            
            # Ch·ªâ ƒë·ªçc t·ªëi ƒëa 2 xe m·ªói frame ƒë·ªÉ kh√¥ng block
            plates_to_detect = plates_to_detect[:2]
            
            for detection in plates_to_detect:
                x1, y1, x2, y2 = detection['vehicle_bbox']
                track_id = detection['track_id']
                
                # TƒÇNG PADDING ƒë·ªÉ bao h·∫øt bi·ªÉn s·ªë (ƒë·∫∑c bi·ªát v·ªõi xe t·∫£i, bus)
                # Padding l·ªõn h∆°n ·ªü ph√≠a d∆∞·ªõi (n∆°i th∆∞·ªùng c√≥ bi·ªÉn s·ªë)
                padding_top = 30
                padding_bottom = 60  # TƒÉng padding d∆∞·ªõi ƒë·ªÉ bao h·∫øt bi·ªÉn s·ªë
                padding_left = 40
                padding_right = 40
                
                crop_x1 = max(0, x1 - padding_left)
                crop_y1 = max(0, y1 - padding_top)
                crop_x2 = min(frame.shape[1], x2 + padding_right)
                crop_y2 = min(frame.shape[0], y2 + padding_bottom)
                
                # ƒê·∫£m b·∫£o k√≠ch th∆∞·ªõc t·ªëi thi·ªÉu
                if crop_x2 - crop_x1 < 100 or crop_y2 - crop_y1 < 80:
                    continue
                
                vehicle_crop = frame[crop_y1:crop_y2, crop_x1:crop_x2].copy()
                
                # ENHANCE ·∫¢NH ƒë·ªÉ detect t·ªët h∆°n (tƒÉng contrast, sharpen)
                if vehicle_crop.size > 0:
                    try:
                        # Chuy·ªÉn sang grayscale n·∫øu c·∫ßn
                        if len(vehicle_crop.shape) == 3:
                            gray = cv2.cvtColor(vehicle_crop, cv2.COLOR_BGR2GRAY)
                        else:
                            gray = vehicle_crop
                        
                        # TƒÉng contrast v√† brightness
                        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
                        enhanced = clahe.apply(gray)
                        
                        # Chuy·ªÉn l·∫°i v·ªÅ BGR n·∫øu c·∫ßn
                        if len(vehicle_crop.shape) == 3:
                            enhanced_bgr = cv2.cvtColor(enhanced, cv2.COLOR_GRAY2BGR)
                        else:
                            enhanced_bgr = enhanced
                        
                        # Th·ª≠ detect v·ªõi ·∫£nh g·ªëc v√† ·∫£nh ƒë√£ enhance
                        best_result = None
                        best_score = 0
                        orig_h, orig_w = vehicle_crop.shape[:2]
                        
                        for test_img in [vehicle_crop, enhanced_bgr]:
                            # Resize n·∫øu qu√° l·ªõn ho·∫∑c qu√° nh·ªè ƒë·ªÉ tƒÉng ƒë·ªô ch√≠nh x√°c
                            h, w = test_img.shape[:2]
                            scale_factor = 1.0
                            
                            if w > 1200 or h > 800:
                                scale_factor = min(1200 / w, 800 / h)
                                new_w = int(w * scale_factor)
                                new_h = int(h * scale_factor)
                                test_img_resized = cv2.resize(test_img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
                            elif w < 200 or h < 150:
                                scale_factor = max(200 / w, 150 / h)
                                new_w = int(w * scale_factor)
                                new_h = int(h * scale_factor)
                                test_img_resized = cv2.resize(test_img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
                            else:
                                test_img_resized = test_img
                            
                            # S·ª≠ d·ª•ng PlateDetector t·ª´ detector.py (Fast-ALPR model)
                            # Khi ƒë√£ ch·ª•p ƒë∆∞·ª£c xe vi ph·∫°m, nh·ªù Fast-ALPR nh·∫≠n di·ªán bi·ªÉn s·ªë ch√≠nh x√°c
                            plate_results = self.plate_detector.detect(test_img_resized)
                            
                            # Log ƒë·ªÉ debug - th·∫•y r√µ model ƒëang ho·∫°t ƒë·ªông
                            if plate_results and len(plate_results) > 0:
                                print(f"[Fast-ALPR] Detected {len(plate_results)} plate(s) for track {track_id}")
                            
                            if plate_results and len(plate_results) > 0:
                                # Ch·ªçn bi·ªÉn s·ªë t·ªët nh·∫•t d·ª±a tr√™n confidence, bounding box v√† text
                                # ∆Øu ti√™n confidence t·ª´ Fast-ALPR ƒë·ªÉ ƒë·∫£m b·∫£o ch√≠nh x√°c
                                for plate_result in plate_results:
                                    plate_text = plate_result['plate']
                                    plate_bbox_crop = plate_result['bbox']
                                    
                                    # L·∫•y confidence t·ª´ Fast-ALPR (n·∫øu c√≥)
                                    plate_confidence = plate_result.get('confidence', 0.5)
                                    detection_conf = plate_result.get('detection_conf', 0.5)
                                    ocr_conf = plate_result.get('ocr_conf', 0.5)
                                    
                                    # Scale l·∫°i bbox v·ªÅ k√≠ch th∆∞·ªõc crop g·ªëc (CH√çNH X√ÅC H√ìA)
                                    px1, py1, px2, py2 = plate_bbox_crop
                                    if scale_factor != 1.0:
                                        # D√πng float ƒë·ªÉ t√≠nh ch√≠nh x√°c tr∆∞·ªõc, sau ƒë√≥ m·ªõi l√†m tr√≤n
                                        px1 = int(round(px1 / scale_factor))
                                        py1 = int(round(py1 / scale_factor))
                                        px2 = int(round(px2 / scale_factor))
                                        py2 = int(round(py2 / scale_factor))
                                    
                                    # ƒê·∫£m b·∫£o n·∫±m trong crop g·ªëc
                                    px1 = max(0, min(px1, orig_w - 1))
                                    py1 = max(0, min(py1, orig_h - 1))
                                    px2 = max(px1 + 1, min(px2, orig_w))
                                    py2 = max(py1 + 1, min(py2, orig_h))
                                    
                                    # Validate bbox h·ª£p l·ªá
                                    if px2 <= px1 or py2 <= py1:
                                        continue
                                    
                                    # T√≠nh ƒëi·ªÉm d·ª±a tr√™n confidence, bounding box v√† text
                                    score = 0
                                    
                                    # 1. ƒêI·ªÇM CHO CONFIDENCE (∆ØU TI√äN CAO NH·∫§T) - ƒê·∫£m b·∫£o ch√≠nh x√°c
                                    # Confidence t·ª´ Fast-ALPR l√† ch·ªâ s·ªë quan tr·ªçng nh·∫•t
                                    score += plate_confidence * 50  # Nh√¢n v·ªõi 50 ƒë·ªÉ c√≥ tr·ªçng s·ªë l·ªõn
                                    score += detection_conf * 20   # Detection confidence c≈©ng quan tr·ªçng
                                    score += ocr_conf * 10          # OCR confidence
                                    
                                    # 2. ƒêi·ªÉm cho ƒë·ªô d√†i text (bi·ªÉn s·ªë ƒë·∫ßy ƒë·ªß)
                                    if len(plate_text) >= 8:
                                        score += 25  # Bonus l·ªõn cho bi·ªÉn s·ªë ƒë·∫ßy ƒë·ªß (8+ k√Ω t·ª±)
                                    elif len(plate_text) >= 6:
                                        score += 15  # Bonus cho bi·ªÉn s·ªë h·ª£p l√Ω (6-7 k√Ω t·ª±)
                                    else:
                                        continue  # B·ªè qua bi·ªÉn s·ªë kh√¥ng ƒë·∫ßy ƒë·ªß (< 6 k√Ω t·ª±)
                                    
                                    # 3. ƒêi·ªÉm cho k√≠ch th∆∞·ªõc bbox (∆∞u ti√™n bbox h·ª£p l√Ω)
                                    bbox_w = px2 - px1
                                    bbox_h = py2 - py1
                                    bbox_area = bbox_w * bbox_h
                                    
                                    # K√≠ch th∆∞·ªõc h·ª£p l√Ω cho bi·ªÉn s·ªë: 80-400px width, 30-100px height
                                    if 80 <= bbox_w <= 400 and 30 <= bbox_h <= 100:
                                        score += 20  # Bonus l·ªõn cho k√≠ch th∆∞·ªõc h·ª£p l√Ω
                                    elif 50 <= bbox_w <= 500 and 20 <= bbox_h <= 120:
                                        score += 10  # Bonus cho k√≠ch th∆∞·ªõc ch·∫•p nh·∫≠n ƒë∆∞·ª£c
                                    
                                    # 4. ƒêi·ªÉm cho t·ª∑ l·ªá khung h√¨nh (bi·ªÉn s·ªë th∆∞·ªùng r·ªông h∆°n cao)
                                    aspect_ratio = bbox_w / bbox_h if bbox_h > 0 else 0
                                    if 2.0 <= aspect_ratio <= 5.0:  # T·ª∑ l·ªá h·ª£p l√Ω cho bi·ªÉn s·ªë
                                        score += 15
                                    elif 1.5 <= aspect_ratio <= 6.0:
                                        score += 8
                                    
                                    # 5. ƒêi·ªÉm cho v·ªã tr√≠ (∆∞u ti√™n bbox ·ªü ph·∫ßn d∆∞·ªõi c·ªßa crop - n∆°i th∆∞·ªùng c√≥ bi·ªÉn s·ªë)
                                    # T√≠nh v·ªã tr√≠ t∆∞∆°ng ƒë·ªëi trong crop (0 = tr√™n c√πng, 1 = d∆∞·ªõi c√πng)
                                    relative_y = (py1 + py2) / 2.0 / orig_h if orig_h > 0 else 0.5
                                    if relative_y > 0.6:  # ·ªû ph·∫ßn d∆∞·ªõi (60% tr·ªü xu·ªëng)
                                        score += 10
                                    elif relative_y > 0.5:  # ·ªû n·ª≠a d∆∞·ªõi
                                        score += 5
                                    
                                    # 6. ƒêi·ªÉm cho di·ªán t√≠ch (∆∞u ti√™n bbox kh√¥ng qu√° nh·ªè)
                                    if bbox_area >= 3000:  # Di·ªán t√≠ch l·ªõn h∆°n = r√µ n√©t h∆°n
                                        score += 10
                                    elif bbox_area >= 2000:  # Di·ªán t√≠ch t·ªëi thi·ªÉu h·ª£p l√Ω
                                        score += 5
                                    
                                    # Ch·ªâ ch·ªçn bi·ªÉn s·ªë c√≥ ƒëi·ªÉm cao h∆°n (∆∞u ti√™n confidence cao)
                                    if score > best_score:
                                        best_result = {
                                            'plate': plate_text,
                                            'bbox': (px1, py1, px2, py2),
                                            'confidence': plate_confidence
                                        }
                                        best_score = score
                        
                        if best_result:
                            plate_text = best_result['plate']
                            plate_bbox_crop = best_result['bbox']
                            plate_conf = best_result.get('confidence', 0.5)
                            
                            # CHUY·ªÇN BBOX V·ªÄ H·ªÜ T·ªåA ƒê·ªò G·ªêC (CH√çNH X√ÅC H√ìA)
                            # Bbox ƒë√£ ƒë∆∞·ª£c scale v·ªÅ crop g·ªëc, gi·ªù chuy·ªÉn v·ªÅ frame g·ªëc
                            px1, py1, px2, py2 = plate_bbox_crop
                            
                            # Chuy·ªÉn bbox v·ªÅ h·ªá t·ªça ƒë·ªô g·ªëc c·ªßa frame (CH√çNH X√ÅC)
                            # D√πng float ƒë·ªÉ t√≠nh ch√≠nh x√°c tr∆∞·ªõc, sau ƒë√≥ m·ªõi l√†m tr√≤n
                            abs_px1 = int(round(crop_x1 + px1))
                            abs_py1 = int(round(crop_y1 + py1))
                            abs_px2 = int(round(crop_x1 + px2))
                            abs_py2 = int(round(crop_y1 + py2))
                            
                            # Validate bbox tr∆∞·ªõc khi l∆∞u - ƒê·∫£m b·∫£o kh√¥ng b·ªã sai
                            h, w = frame.shape[:2]
                            abs_px1 = max(0, min(abs_px1, w - 1))
                            abs_py1 = max(0, min(abs_py1, h - 1))
                            abs_px2 = max(abs_px1 + 1, min(abs_px2, w))
                            abs_py2 = max(abs_py1 + 1, min(abs_py2, h))
                            
                            # Ki·ªÉm tra bbox h·ª£p l·ªá tr∆∞·ªõc khi l∆∞u
                            if abs_px2 > abs_px1 and abs_py2 > abs_py1:
                                # L∆∞u k·∫øt qu·∫£ ch√≠nh x√°c t·ª´ Fast-ALPR
                                detection['plate'] = plate_text
                                detection['plate_bbox'] = (abs_px1, abs_py1, abs_px2, abs_py2)
                                
                                # Log k·∫øt qu·∫£ t·ª´ Fast-ALPR v·ªõi confidence
                                print(f"[Fast-ALPR] Track {track_id}: Plate={plate_text} (conf={plate_conf:.2f}), "
                                      f"BBox=({abs_px1},{abs_py1},{abs_px2},{abs_py2}) - CH√çNH X√ÅC")
                                
                                # L∆∞u v√†o cache ƒë·ªÉ t√°i s·ª≠ d·ª•ng
                                self.plate_cache[track_id] = {
                                    'plate': plate_text,
                                    'bbox': detection['plate_bbox'],
                                    'frame_count': 0,
                                    'confidence': plate_conf
                                }
                            else:
                                print(f"[Fast-ALPR] Track {track_id}: BBox kh√¥ng h·ª£p l·ªá, b·ªè qua")
                    except Exception as e:
                        # In l·ªói ƒë·ªÉ debug (kh√¥ng b·ªè qua ho√†n to√†n)
                        print(f"[PLATE DETECT ERROR] {e}")
                        import traceback
                        traceback.print_exc()
        
        # C·∫≠p nh·∫≠t cache age
        for track_id in list(self.plate_cache.keys()):
            self.plate_cache[track_id]['frame_count'] += 1
            if self.plate_cache[track_id]['frame_count'] >= self.plate_cache_max_age:
                del self.plate_cache[track_id]
        
        return detections
    
    def draw_detections(self, frame, detection, speed=None, speed_limit=40):
        """
        V·∫Ω th√¥ng tin xe, bi·ªÉn s·ªë v√† t·ªëc ƒë·ªô l√™n frame
        T·ªëi ∆∞u cho web: V·∫Ω nhanh, kh√¥ng block
        """
        # L·∫•y th√¥ng tin
        x1, y1, x2, y2 = detection['vehicle_bbox']
        vehicle_class = detection['vehicle_class']
        confidence = detection['confidence']
        track_id = detection['track_id']
        plate = detection.get('plate')
        plate_bbox = detection.get('plate_bbox')
        
        # M√†u s·∫Øc theo lo·∫°i xe
        color_map = {
            'car': (0, 255, 0),        # Xanh l√°
            'motorcycle': (255, 0, 0),  # Xanh d∆∞∆°ng
            'bus': (0, 165, 255),       # Cam
            'truck': (0, 255, 255)      # V√†ng
        }
        color = color_map.get(vehicle_class, (255, 255, 255))
        
        # N·∫øu c√≥ t·ªëc ƒë·ªô v√† v∆∞·ª£t qu√° gi·ªõi h·∫°n ‚Üí m√†u ƒë·ªè
        is_violation = False
        if speed is not None and speed > speed_limit:
            color = (0, 0, 255)  # ƒê·ªè
            is_violation = True
        
        # Ki·ªÉm tra t·ªça ƒë·ªô h·ª£p l·ªá
        h, w = frame.shape[:2]
        x1 = max(0, min(x1, w - 1))
        y1 = max(0, min(y1, h - 1))
        x2 = max(x1 + 1, min(x2, w))
        y2 = max(y1 + 1, min(y2, h))
        
        if x2 <= x1 or y2 <= y1:
            return frame
        
        # V·∫Ω bounding box xe - VI·ªÄN M·ªéNG NH·∫§T (thickness = 1)
        thickness = 1  # M·ªèng nh·∫•t nh∆∞ng v·∫´n ƒë·ªß nh√¨n
        cv2.rectangle(frame, (x1, y1), (x2, y2), color, thickness)
        
        # T·∫°o label - CH·ªà HI·ªÜN T·ªêC ƒê·ªò, KH√îNG HI·ªÜN BI·ªÇN S·ªê V√Ä "VI PH·∫†M"
        label_parts = []
        
        # Ch·ªâ hi·ªán t·ªëc ƒë·ªô n·∫øu c√≥
        if speed is not None:
            label_parts.append(f"{speed:.1f} km/h")
        
        # N·∫øu kh√¥ng c√≥ t·ªëc ƒë·ªô, kh√¥ng hi·ªán g√¨
        if not label_parts:
            return frame
        
        label = " ".join(label_parts)
        
        # V·∫Ω background v√† text - FONT NH·ªé H∆†N
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.4  # Nh·ªè h∆°n (t·ª´ 0.6 xu·ªëng 0.4)
        thickness_text = 1  # Text m·ªèng h∆°n
        (text_width, text_height), baseline = cv2.getTextSize(label, font, font_scale, thickness_text)
        
        text_x = max(0, min(x1 + 3, w - text_width - 3))
        text_y = max(text_height + 3, min(y1 - 5, h - 3))
        
        bg_x1 = max(0, min(x1, w - text_width - 6))
        bg_y1 = max(0, min(y1 - text_height - 8, h - text_height - 3))
        bg_x2 = min(w, bg_x1 + text_width + 6)
        bg_y2 = min(h, bg_y1 + text_height + 8)
        
        if bg_x2 > bg_x1 and bg_y2 > bg_y1:
            cv2.rectangle(frame, (bg_x1, bg_y1), (bg_x2, bg_y2), color, -1)
        
        cv2.putText(frame, label, (text_x, text_y), 
                   font, font_scale, (255, 255, 255), thickness_text)
        
        # KH√îNG V·∫º BBOX BI·ªÇN S·ªê - Ch·ªâ t·ªëi ∆∞u ph·∫ßn ch·ª•p bi·ªÉn s·ªë
        # Bi·ªÉn s·ªë v·∫´n ƒë∆∞·ª£c detect v√† l∆∞u trong detection['plate'] v√† detection['plate_bbox']
        # nh∆∞ng kh√¥ng hi·ªÉn th·ªã text box nh·ªè tr√™n frame ƒë·ªÉ t·ªëi ∆∞u hi·ªáu su·∫•t
        
        return frame
